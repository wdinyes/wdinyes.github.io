---
layout: post
title:  "Broken Pipe Enshittification"
date:   2025-08-29 05:00:00 -0700
categories: general
---

This week at work, we had training about using AI tools to generate code.

I cannot begin to tell you how absurdly myopic this felt to me.

I've been programming, either as my direct work task, or an ancillary task to my main function, for over 30 years now.

My thoughts on using AI for a first draft are not fully formed, but they basically come down to, we're breaking the pipeline for new programmers.

No, I'm serious.  There will no longer be a pipeline for new programmers.

What do I mean?  If you know a programmer, you know that they're largely learn-as-you-go folks.  If I am tasked with writing new code to integrate with a new platform, say, Iceberg, or Kafka, or whatever new platform has elbowed it's way into an already crowded market, then my first step is to write some basic code to get the hang of the new API.  Sure, I can take some training, and I can watch some videos, but at the end of the day, if it's something that needs to be **done**, the best way to learn it is to **do it**.

In the case of software development, which is fairly low stakes in terms of something going wrong during development (that is to say, I am unlikely to kill someone with my proof of concept), I am free to make errors, to learn efficiencies, and to identify how this new tool or language fits into my existing toolset and thus become a better, more experienced programmer.

That process of trial and error is ***absolutely necessary*** to becoming an expert.  Not just in programming, but, frankly, in everything.

The problem with AI slop programming is that it eliminates the initial trial and error stage.  AI tools will shit out a *functional* code stack for a variety of platforms and languages and integrations with ease.  

So what?

So this: who evaluates the shit?  Who identifies if it's filled with obfuscated trojans or poor security implementations or just plain over-engineered crap?

The expert programmer, of course, you say.

And how did the expert become the expert?

Back to the training sessions, the instructor was going on about how to use the AI tools.  Ask it detailed questions.  Get it to focus on specific tasks in the goal.

Yes, alright, I say, but . . . again . . . who knows how to craft the correct questions to lead the AI ass to water?

The expert programmer, of course, you say.

And again, I ask, how did the expert become the expert?

You see, by using these AI tools, the profession of programming has functionally said, "We have enough experts, we don't need any more, we can let AI do the shit work, and crap out the shit code, and then we can let our experts focus on the expert task of making sure the code is sound and not riddled with inefficiencies and security holes."

So, functionally, what I'm saying is, AI tools for programming (and frankly dozens of other disciplines) are breaking the pipeline to becoming an expert.

If I can ask AI to draw me whatever picture I want, how do I learn to draw?

If I can ask AI to compose my music, to write my books, to voiceover my videos, to, essentially, create what I cannot, how do I learn to be a creator?

Eventually, the experts move on.  It always happens.  But if we use AI to shit out the novice work, uncritically, and with no one left to evaluate the correctness of the solution, where are we then?  At the mercy of a toolset written by uncritical people, with uncritical minds.

Have I used AI tools myself?  Yes.  I used them most recently to craft a shit-ton of questions for assessments.  From this epic pile of crap, I filtered out the questions that were clearly hallucinations, the ones that were too simplistic, the ones that were, frankly, unusable.  I was the crap filter.  Because I am the expert.  And then I took these questions to even more focused experts and they filtered out even more.  Out of the huge pile of shit, I was able to salvage maybe a tenth of the questions.  And then I re-wrote most of what was left because AI tooling really chooses some weird ass phrasing which often leads to questions which contain the answer, which is not what I was looking for.  Naturally.

Was it faster than writing every question from scratch?  Certainly.  Frankly, I needed a huge pile of shit to start with, because in the end I needed a significant pile of gold.  That's how mining works, you know.  Visit a real mine sometime, you'll see.  I will admit that it let me be a one-man-band for the first stage, which was . . . okay I guess.  Still would have been nice to spend some time, I dunno, training another person in the ways of developing a certification that actual means something.  Experts can always use more experts.  (Any expert saying otherwise is a tool.)

But if I needed a small anthill of gold, it probably would have been much faster to write them directly, and skip the panning-for-gold steps.

But I still needed experts.  Either myself to write them directly, or a collection of them to sift through a pile.

And I am unclear where these experts will come from in the future.  This move-fast-break-shit mentality just ends up with a lot of broken shit at the end of the day.

But I am sure an apologist will "helpfully" explain to me why I'm wrong.  Probably using Grok.
